{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3378e355-5358-41d4-abab-c25b15214df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f905c90e-1a5e-4803-b37d-168fec3767bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and',\n",
    "    'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being',\n",
    "    'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\",\n",
    "    'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during',\n",
    "    'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\",\n",
    "    'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here',\n",
    "    \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i',\n",
    "    \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\",\n",
    "    'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    "    'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought',\n",
    "    'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she',\n",
    "    \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than',\n",
    "    'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then',\n",
    "    'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\",\n",
    "    'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was',\n",
    "    \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what',\n",
    "    \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who',\n",
    "    \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you',\n",
    "    \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself',\n",
    "    'yourselves'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5f5e2c-7b0f-4a10-acf9-4258203d85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text):\n",
    "    \"\"\"\n",
    "    Clean and tokenize text without using external libraries\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    #replacing non alphabatical chars without use of regex\n",
    "    cleaned_text = \"\"\n",
    "    for char in text:\n",
    "        if char.isalpha() or char.isspace():\n",
    "            cleaned_text += char\n",
    "        else:\n",
    "            cleaned_text += \" \"\n",
    "    \n",
    "    tokens = cleaned_text.split()\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838f606f-cc52-4627-b529-78650672b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_freq_dict(tokens):\n",
    "    \"\"\"\n",
    "    Create a dictionary of word frequencies\n",
    "    \"\"\"\n",
    "    word_freq = {}\n",
    "    for token in tokens:\n",
    "        if token in word_freq:\n",
    "            word_freq[token] += 1\n",
    "        else:\n",
    "            word_freq[token] = 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27b8d67-82de-4d6c-90e9-12f27735263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Load data from TSV file without using pandas\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        header = next(reader)\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                genre = row[0]\n",
    "                description = row[1]\n",
    "                data.append((genre, description))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d3e7d9-775b-4351-8a47-70337eefebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(training_data):\n",
    "    \"\"\"\n",
    "    Train a Naive Bayes classifier from scratch\n",
    "    \"\"\"\n",
    "    #count of occurrences of each word per genre\n",
    "    word_counts_per_genre = {}\n",
    "    genre_counts = {}\n",
    "    vocabulary = set()\n",
    "    \n",
    "    for genre, description in training_data:\n",
    "        #updating genre counts\n",
    "        if genre in genre_counts:\n",
    "            genre_counts[genre] += 1\n",
    "        else:\n",
    "            genre_counts[genre] = 1\n",
    "            word_counts_per_genre[genre] = {}\n",
    "        \n",
    "        #processing the description\n",
    "        tokens = clean_and_tokenize(description)\n",
    "        for token in tokens:\n",
    "            vocabulary.add(token)\n",
    "            if token in word_counts_per_genre[genre]:\n",
    "                word_counts_per_genre[genre][token] += 1\n",
    "            else:\n",
    "                word_counts_per_genre[genre][token] = 1\n",
    "    \n",
    "    #calc word probabilities using the technique Laplace smoothing, A new thing for me\n",
    "    vocab_size = len(vocabulary)\n",
    "    word_probs_per_genre = {}\n",
    "    total_documents = len(training_data)\n",
    "    \n",
    "    for genre in genre_counts:\n",
    "        word_probs_per_genre[genre] = {}\n",
    "        total_words_in_genre = sum(word_counts_per_genre[genre].values())\n",
    "        \n",
    "        word_probs_per_genre[genre]['__prior__'] = math.log(genre_counts[genre] / total_documents)\n",
    "        \n",
    "        #calc conditional probabilities for each word\n",
    "        for word in vocabulary:\n",
    "            count = word_counts_per_genre[genre].get(word, 0)\n",
    "            #Laplace smoothing (also known as add one smoothing)\n",
    "            prob = (count + 1) / (total_words_in_genre + vocab_size)\n",
    "            word_probs_per_genre[genre][word] = math.log(prob)\n",
    "    \n",
    "    return word_probs_per_genre, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a973a49c-7ff2-493d-a96b-dc1c3f09cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(description, word_probs_per_genre, vocabulary):\n",
    "    \"\"\"\n",
    "    Predict genre for a given description\n",
    "    \"\"\"\n",
    "    tokens = clean_and_tokenize(description)\n",
    "    scores = {}\n",
    "    \n",
    "    #calc score for each genre\n",
    "    for genre in word_probs_per_genre:\n",
    "        #starting with prior probability\n",
    "        scores[genre] = word_probs_per_genre[genre]['__prior__']\n",
    "        \n",
    "        #add log probabilities for each word\n",
    "        for token in tokens:\n",
    "            if token in vocabulary:  #only consider words in given vocabulary\n",
    "                scores[genre] += word_probs_per_genre[genre].get(token, 0)\n",
    "    \n",
    "    #return genre with highest score\n",
    "    return max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c36672-7e88-4e13-9728-971c0b74b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(test_data, word_probs_per_genre, vocabulary):\n",
    "    \"\"\"\n",
    "    Evaluate classifier performance on test data\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for genre, description in test_data:\n",
    "        #initialize checks if not seen genre before\n",
    "        if genre not in results:\n",
    "            results[genre] = {'correct': 0, 'incorrect': 0, 'total': 0}\n",
    "        \n",
    "        #increment total count for genre\n",
    "        results[genre]['total'] += 1\n",
    "        \n",
    "        #making prediction\n",
    "        predicted_genre = predict_genre(description, word_probs_per_genre, vocabulary)\n",
    "        \n",
    "        #update correct/incorrect counts\n",
    "        if predicted_genre == genre:\n",
    "            results[genre]['correct'] += 1\n",
    "        else:\n",
    "            results[genre]['incorrect'] += 1\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8e1578-46b0-4817-a170-e093d7a13a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    training_data = load_data('film-genres-train.csv')\n",
    "    test_data = load_data('film-genres-test.csv')\n",
    "    \n",
    "    print(\"Training classifier...\")\n",
    "    word_probs_per_genre, vocabulary = train_naive_bayes(training_data)\n",
    "    \n",
    "    print(\"Evaluating classifier...\")\n",
    "    results = evaluate_classifier(test_data, word_probs_per_genre, vocabulary)\n",
    "    \n",
    "    print(\"\\nClassification Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Genre':<12} {'Correct':<10} {'Incorrect':<10} {'Total':<10} {'Accuracy (%)':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_total = 0\n",
    "    \n",
    "    for genre, counts in results.items():\n",
    "        accuracy = (counts['correct'] / counts['total']) * 100 if counts['total'] > 0 else 0\n",
    "        print(f\"{genre:<12} {counts['correct']:<10} {counts['incorrect']:<10} {counts['total']:<10} {accuracy:.2f}\")\n",
    "        total_correct += counts['correct']\n",
    "        total_total += counts['total']\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    overall_accuracy = (total_correct / total_total) * 100 if total_total > 0 else 0\n",
    "    print(f\"{'Overall':<12} {total_correct:<10} {total_total - total_correct:<10} {total_total:<10} {overall_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b00fea-132d-4f75-b4f5-ce067340e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "Evaluating classifier...\n",
      "\n",
      "Classification Results:\n",
      "------------------------------------------------------------\n",
      "Genre        Correct    Incorrect  Total      Accuracy (%)\n",
      "------------------------------------------------------------\n",
      "Documentary  527        125        652        80.83\n",
      "Comedy       510        614        1124       45.37\n",
      "Drama        1990       217        2207       90.17\n",
      "Horror       62         190        252        24.60\n",
      "Western      197        42         239        82.43\n",
      "------------------------------------------------------------\n",
      "Overall      3286       1188       4474       73.45\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c1737-ddf7-4254-9059-bc8e3ca5a24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183559f-d206-408e-a467-6365f3017638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67486890-ae47-486f-a807-97922eddb557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
